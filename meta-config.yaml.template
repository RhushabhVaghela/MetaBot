# MegaBot Configuration Template
# Copy this file to mega-config.yaml and customize for your setup

system:
  name: "MegaBot"
  local_only: true
  bind_address: "127.0.0.1"
  telemetry: false
  default_mode: "plan"  # Options: plan, build, ask, loki
  admin_phone: "+1234567890" # For IVR escalation
  dnd_start: 22 # 10 PM
  dnd_end: 7    # 7 AM


adapters:
  openclaw:
    host: "127.0.0.1"
    port: 18789
    auth_token: ""  # Set via MEGABOT_AUTH_TOKEN env var
    bridge_type: websocket
    database_url: "sqlite:///megabot.db"
    vector_db: pgvector
    
  memu:
    host: "127.0.0.1"
    port: 3000
    auth_token: ""
    bridge_type: websocket
    database_url: "sqlite:///:memory:"
    vector_db: sqlite
    
  mcp:
    host: "127.0.0.1"
    port: 3000
    auth_token: ""
    bridge_type: websocket
    database_url: "sqlite:///megabot.db"
    vector_db: pgvector
    servers: []
      # Example MCP servers:
      # - name: filesystem
      #   command: npx
      #   args: ["-y", "@modelcontextprotocol/server-filesystem", "/path/to/files"]
      # - name: github
      #   command: npx
      #   args: ["-y", "@modelcontextprotocol/server-github"]
      # - name: google-services
      #   command: npx
      #   args: ["-y", "@modelcontextprotocol/server-gdrive"]

paths:
  external_repos: "/tmp/mock_repos"

policies:
  allow:
    - "git status"  # Commands that don't require approval
  deny: []  # Commands that are always blocked
  # Use "*" to allow/deny ALL commands (use with caution)

admins:
  - "admin"  # User IDs that can run !commands

# Optional: LLM Configuration
llm_profiles:
  default:
    provider: "ollama"
    api_key: "local"
    chat_model: "llama3"
    base_url: "http://127.0.0.1:11434/v1"
